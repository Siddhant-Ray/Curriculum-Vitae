@inproceedings{dietmuller2022new,
author = {Dietm√ºller, Alexander and \textbf{Ray}, \textbf{Siddhant} and Jacob, Romain and Vanbever, Laurent},
title = {A New Hope for Network Model Generalization},
year = {2022},
isbn = {9781450398992},
url = {https://doi.org/10.1145/3563766.3564104},
doi = {10.1145/3563766.3564104},
abstract = {Generalizing machine learning (ML) models for network traffic dynamics tends to be considered a lost cause. Hence for every new task, we design new models and train them on model-specific datasets closely mimicking the deployment environments. Yet, an ML architecture called Transformer has enabled previously unimaginable generalization in other domains. Nowadays, one can download a model pre-trained on massive datasets and only fine-tune it for a specific task and context with comparatively little time and data. These fine-tuned models are now state-of-the-art for many benchmarks.We believe this progress could translate to networking and propose a Network Traffic Transformer (NTT), a transformer adapted to learn network dynamics from packet traces. Our initial results are promising: NTT seems able to generalize to new prediction tasks and environments. This study suggests there is still hope for generalization through future research.},
booktitle = {Proceedings of the 21st ACM Workshop on Hot Topics in Networks},
keywords = {packet-level modeling, transformer},
location = {Austin, Texas},
}

@article{ray2020machine,
  title={Machine learning based cell association for mMTC 5G communication networks},
  author={\textbf{Ray}, \textbf{Siddhant} and Bhattacharyya, Budhaditya},
  journal={International Journal of Mobile Network Design and Innovation},
  volume={10},
  number={1},
  pages={10--16},
  year={2020},
  publisher={Inderscience Publishers (IEL)},
}
